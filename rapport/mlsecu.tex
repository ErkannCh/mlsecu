\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{lmodern}
\usepackage{microtype}

\usepackage{geometry}
\geometry{margin=2.5cm}

\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{amsmath,amssymb}

\usepackage[hidelinks]{hyperref}

\sisetup{
  round-mode=places,
  round-precision=3
}

\newcommand{\ReportTitle}{CYBERML -- Project 1 : Classification, détection d'anomalies et attaques adversariales}
\newcommand{\DatasetName}{CIC IoT-DIAD 2024 (Flow Based Features)}
\newcommand{\AcademicYear}{2025--2026}
\newcommand{\CourseName}{CYBERML}
\newcommand{\LecturerName}{Pierre Parrend}
\newcommand{\Authors}{\textit{\`a compléter}}

\begin{document}
\pagenumbering{gobble}

\begin{titlepage}
  \centering
  \vspace*{2cm}
  {\LARGE \ReportTitle\par}
  \vspace{0.8cm}
  {\large \DatasetName\par}
  \vspace{1.5cm}

  \begin{tabular}{rl}
    \textbf{Cours :} & \CourseName \\
    \textbf{Année :} & \AcademicYear \\
    \textbf{Enseignant :} & \LecturerName \\
    \textbf{Auteurs :} & \Authors \\
  \end{tabular}

  \vfill
  {\large \today\par}
\end{titlepage}

\pagenumbering{roman}

\section*{Résumé}
Ce rapport présente une chaîne de traitement \emph{batch} pour l'analyse de données de flux réseau issues du dataset \DatasetName{} \cite{cic_iot_diad_2024}, avec deux objectifs : (i) détecter des attaques via détection d'anomalies non supervisée, et (ii) classifier les attaques (binaire puis multi-classes) afin de \emph{tracker} des familles et sous-types.
Trois méthodes non supervisées sont comparées (Isolation Forest \cite{liu2008isolationforest}, One-Class SVM \cite{scholkopf2001ocsvm}, score de reconstruction PCA \cite{jolliffe2002pca}) et trois méthodes supervisées (régression logistique, forêt aléatoire, XGBoost \cite{chen2016xgboost}).
Sur la tâche binaire \emph{Benign vs Attack}, XGBoost obtient une AUPRC de \num{0.982} tandis que la PCA reconstruction fournit la meilleure balanced accuracy (\num{0.884}) avec un très faible taux de faux positifs.
En multi-classes, XGBoost atteint une balanced accuracy de \num{0.784} au niveau \emph{familles}, et la régression logistique une balanced accuracy de \num{0.720} au niveau \emph{sous-types} (subset filtré).
Enfin, une étude d'attaque adversariale FGSM \cite{goodfellow2015fgsm} sur la régression logistique met en évidence une forte dégradation : l'accuracy robuste chute de \num{0.728} à \num{0.172} pour $\varepsilon=\num{0.1}$.

\section*{Abstract}
This report describes a batch ML pipeline for network-flow cybersecurity analytics on the \DatasetName{} dataset \cite{cic_iot_diad_2024}. We address (i) unsupervised anomaly detection for attack detection and (ii) supervised classification for attack tracking (binary, then multiclass at family and subtype levels).
We benchmark three unsupervised methods (Isolation Forest \cite{liu2008isolationforest}, One-Class SVM \cite{scholkopf2001ocsvm}, PCA reconstruction error \cite{jolliffe2002pca}) and three supervised classifiers (logistic regression, random forest, XGBoost \cite{chen2016xgboost}).
On \emph{Benign vs Attack}, XGBoost reaches \num{0.982} AUPRC, while PCA reconstruction provides the best balanced accuracy (\num{0.884}) with very few false positives.
For multiclass, XGBoost yields \num{0.784} balanced accuracy at the family level, and logistic regression \num{0.720} at the (filtered) subtype level.
Finally, an FGSM adversarial study \cite{goodfellow2015fgsm} on logistic regression shows a sharp robustness drop: robust accuracy falls from \num{0.728} to \num{0.172} at $\varepsilon=\num{0.1}$.

\newpage
\tableofcontents
\listoffigures
\listoftables
\newpage

\pagenumbering{arabic}

\section{Introduction et contexte cybersécurité}
\subsection{Détection vs suivi d'attaques}
Dans un SOC, l'objectif n'est pas seulement de détecter un événement malveillant, mais aussi de qualifier l'incident et d'en suivre l'évolution : une alerte \emph{binaire} (attaque/normal) soutient la détection précoce, tandis qu'une classification \emph{multi-classes} permet d'orienter l'analyse (famille d'attaque, puis sous-type).
Ces deux niveaux correspondent à des exigences opérationnelles distinctes : (i) minimiser les faux négatifs (attaques manquées) en détection, tout en maîtrisant les faux positifs (alert fatigue), et (ii) fournir un \emph{signal de suivi} suffisamment stable pour déclencher des playbooks de réponse.

\subsection{Modèles ML sur des caractéristiques de flux}
Le dataset étudié fournit des caractéristiques de flux réseau (flow-based) extraites de PCAP : volumes, durées, statistiques de paquets, etc.
Ces représentations sont adaptées au traitement \emph{batch} et à l'apprentissage supervisé, mais posent des défis typiques : forte dimension, distributions hétérogènes, et risque de fuite de données lorsque des flows quasi-identiques (issus du même fichier) se retrouvent en train et test.

\subsection{Enjeux méthodologiques : éviter la fuite de données}
Un split aléatoire par lignes peut sur-estimer la performance si des flows d'un même fichier (donc très corrélés) sont mélangés entre train/test.
Nous adoptons un split \emph{par fichier} via \texttt{GroupShuffleSplit} (group split) pour obtenir une évaluation plus crédible : un fichier de flows est soit dans le train, soit dans le test.

\section{Présentation et caractérisation du dataset}
\subsection{Dataset \DatasetName{}}
Le dataset \DatasetName{} \cite{cic_iot_diad_2024} contient des fichiers CSV de caractéristiques de flux, organisés par familles et sous-types d'attaques.
Dans ce projet, les familles ciblées sont : Benign, BruteForce, DDoS, DoS, Mirai, Recon, Spoofing, Web-Based (8 familles).

\subsection{Chargement RAM-safe et subset expérimental}
Pour rendre l'analyse exécutable sur une machine limitée, le notebook implémente un chargement \emph{RAM-safe} par \emph{budgets} :
(i) \num{10000} lignes max par fichier CSV, (ii) \num{60000} lignes max par famille, (iii) \num{300000} lignes max au total.
Après nettoyage (typage numérique, suppression des NaN et des valeurs infinies), le subset chargé contient \num{274287} flows et \num{77} variables numériques (hors labels).
Le split \emph{par fichier} est réalisé sur \num{34} groupes (fichiers présents dans le subset).

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/dataset_family_distribution.png}
  \caption{Répartition des familles dans le subset chargé (budgets RAM-safe). Le cap par famille (\num{60000}) conduit à une répartition non représentative du dataset complet.}
  \label{fig:dataset-family-dist}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/dataset_subtype_distribution.png}
  \caption{Sous-types les plus fréquents dans le subset chargé (budgets RAM-safe). Dans ce subset, certaines familles sont dominées par un seul sous-type (ordre de lecture des fichiers + cap par famille).}
  \label{fig:dataset-subtype-dist}
\end{figure}

\begin{table}[H]
  \centering
  \caption{Synthèse du subset utilisé : nombre de flows chargés par famille (après nettoyage) et nombre de fichiers CSV disponibles dans le dataset local.}
  \label{tab:dataset-family}
  \resizebox{\textwidth}{!}{\input{tables/dataset_family.tex}}
\end{table}

\subsection{Déséquilibre et implications métriques}
Le subset chargé est déséquilibré au niveau \emph{familles} (e.g. BruteForce $\ll$ DDoS/DoS/Mirai).
La tâche binaire \emph{Benign vs Attack} présente un déséquilibre inverse des scénarios usuels : la classe \emph{Attack} est majoritaire dans le subset, conséquence du cap par famille (Fig.~\ref{fig:dataset-family-dist}).
Dans ce contexte, l'accuracy peut être trompeuse ; nous reportons systématiquement : précision, rappel, AUPRC, balanced accuracy et MCC.

\section{Chaîne complète de traitement des données}
\subsection{Prétraitement}
Le chargement applique les étapes suivantes :
\begin{itemize}
  \item \textbf{Sélection de variables} : exclusion des colonnes identifiantes (\emph{Flow ID}, adresses IP, ports, timestamp) pour limiter les fuites et les artefacts de collection.
  \item \textbf{Typage et nettoyage} : conversion en numérique, suppression des valeurs infinies et des lignes contenant des valeurs manquantes.
  \item \textbf{Réduction mémoire} : conversion en \texttt{float32} et sous-échantillonnage contrôlé par budgets.
\end{itemize}

\subsection{Feature engineering}
Les caractéristiques sont utilisées telles quelles (features de flux), puis standardisées par un \texttt{StandardScaler} (centrage-réduction) afin d'homogénéiser l'échelle des variables, ce qui est particulièrement important pour les méthodes à base de distance ou de marge (SVM, PCA, régression logistique).

\subsection{Séparation train/test (group split)}
Pour chaque scénario, le split est réalisé par fichier (group split) avec un taux de test de 20\%.
Le split impose que toutes les classes soient présentes dans le \emph{train} (contrainte nécessaire pour les classifieurs multi-classes), mais il ne garantit pas que toutes les classes apparaissent en test ; cette limite est discutée en Section~\ref{sec:discussion}.

\subsection{Définition des scénarios}
Trois scénarios sont considérés :
\begin{itemize}
  \item \textbf{Binaire} : $y=1$ si \texttt{attack\_family}$\neq$Benign, sinon $y=0$.
  \item \textbf{Familles} : $y$ correspond à l'identifiant de famille (8 classes).
  \item \textbf{Sous-types} : pour éviter des classes trop rares et des splits instables, les sous-types sont filtrés (min \num{15000} occurrences dans \texttt{df\_all}), les \num{10} plus fréquents sont conservés, les autres sont regroupés sous \emph{Other}, puis chaque classe est plafonnée à \num{10000} flows.
\end{itemize}

\section{Méthodes de détection d'anomalies}
\subsection{Isolation Forest}
Isolation Forest \cite{liu2008isolationforest} isole les points atypiques via des arbres aléatoires ; les anomalies sont isolées en peu de coupures et reçoivent un score élevé.
Le modèle est entraîné uniquement sur du trafic Benign, puis évalué sur le test complet.

\subsection{One-Class SVM}
One-Class SVM \cite{scholkopf2001ocsvm} estime le support d'une distribution (ici, Benign) et détecte les points situés en dehors de la frontière.
Cette méthode peut être efficace mais sensible au choix de noyau et à l'échelle des variables, d'où l'intérêt de la standardisation.

\subsection{PCA + erreur de reconstruction}
La PCA \cite{jolliffe2002pca} apprend un sous-espace expliquant 95\% de la variance du trafic Benign.
Un flow est considéré comme anomalie si son erreur de reconstruction dépasse un seuil (ici le 95e percentile des erreurs de reconstruction sur le train Benign).
Cette approche est simple, interprétable et robuste pour des anomalies qui dévient significativement du sous-espace normal.

\section{Méthodes de classification}
\noindent Les implémentations utilisées proviennent principalement de \texttt{scikit-learn} \cite{pedregosa2011scikit} et \texttt{xgboost} \cite{chen2016xgboost}.

\subsection{Régression logistique}
La régression logistique (multinomiale en multi-classes) fournit un classifieur linéaire probabiliste.
Elle est rapide, bien calibrée et sert de baseline solide ; elle est cependant sensible aux perturbations adversariales (Section~\ref{sec:adv}).

\subsection{Forêt aléatoire}
Les forêts aléatoires agrègent des arbres de décision entraînés sur des sous-échantillons ; elles capturent des non-linéarités tout en restant relativement robustes au bruit.
Le paramètre \texttt{class\_weight} est activé pour limiter l'effet de déséquilibre.

\subsection{XGBoost}
XGBoost \cite{chen2016xgboost} réalise un boosting d'arbres de décision, souvent performant sur des données tabulaires.
Nous utilisons \texttt{tree\_method=hist} (CPU) pour l'efficacité, et des hyperparamètres adaptés à un compromis biais/variance.

\section{Benchmark expérimental}
\subsection{Métriques}
Pour la tâche binaire, on calcule :
\begin{itemize}
  \item \textbf{Précision} et \textbf{rappel} sur la classe \emph{Attack}.
  \item \textbf{AUPRC} (aire sous la courbe précision--rappel), adaptée aux déséquilibres et à l'optimisation de seuil.
  \item \textbf{Balanced accuracy} : $\mathrm{BA}=\frac{1}{2}(\mathrm{TPR}+\mathrm{TNR})$.
  \item \textbf{MCC} \cite{matthews1975mcc}, corrélation entre prédictions et vérité terrain :
  \[
    \mathrm{MCC}=\frac{TP\cdot TN - FP\cdot FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}.
  \]
\end{itemize}
En multi-classes, on rapporte précision/rappel macro et pondérés, balanced accuracy, MCC et une AUPRC macro (one-vs-rest) sur les classes présentes.

\subsection{Détection binaire : non supervisé}
Les modèles non supervisés sont entraînés uniquement sur Benign puis évalués sur le test complet.
Le tableau~\ref{tab:bin-unsup} montre que la PCA reconstruction obtient la meilleure balanced accuracy (\num{0.884}) et un très faible nombre de faux positifs (FP=\num{326}), ce qui est intéressant du point de vue opérationnel.

\begin{table}[H]
  \centering
  \caption{Résultats binaire (non supervisé) sur le test : métriques et matrice de confusion agrégée.}
  \label{tab:bin-unsup}
  \resizebox{\textwidth}{!}{\input{tables/results_binary_unsupervised.tex}}
\end{table}

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\linewidth]{figures/confusion_unsup_isoforest.png}
    \caption{Isolation Forest}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\linewidth]{figures/confusion_unsup_ocsvm.png}
    \caption{One-Class SVM}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\linewidth]{figures/confusion_unsup_pca.png}
    \caption{PCA (reconstruction)}
  \end{subfigure}
  \caption{Matrices de confusion -- détection binaire non supervisée (test). Les faux positifs (Benign$\rightarrow$Attaque) se traduisent directement en alertes inutiles.}
  \label{fig:cm-bin-unsup}
\end{figure}

\subsection{Détection binaire : supervisé}
Le tableau~\ref{tab:bin-sup} compare les trois classifieurs supervisés.
XGBoost maximise l'AUPRC (\num{0.982}) et le rappel (\num{0.989}), mais avec un coût important en faux positifs (FP=\num{6685} sur \num{10000} Benign), ce qui pénalise la balanced accuracy (\num{0.660}).
À l'inverse, la régression logistique réduit fortement les faux positifs (FP=\num{2414}) au prix d'un rappel plus faible (\num{0.722}).

\begin{table}[H]
  \centering
  \caption{Résultats binaire (supervisé) sur le test : métriques et matrice de confusion agrégée.}
  \label{tab:bin-sup}
  \resizebox{\textwidth}{!}{\input{tables/results_binary_supervised.tex}}
\end{table}

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\linewidth]{figures/confusion_sup_logreg.png}
    \caption{Régression logistique}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\linewidth]{figures/confusion_sup_rf.png}
    \caption{Forêt aléatoire}
  \end{subfigure}
  \begin{subfigure}{0.32\textwidth}
    \includegraphics[width=\linewidth]{figures/confusion_sup_xgb.png}
    \caption{XGBoost}
  \end{subfigure}
  \caption{Matrices de confusion -- détection binaire supervisée (test). Un modèle à fort rappel peut rester difficilement exploitable si le taux de faux positifs est trop élevé (alert fatigue).}
  \label{fig:cm-bin-sup}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/pr_curves_binary_supervised.png}
  \caption{Courbes précision--rappel en binaire supervisé. Elles permettent de choisir un seuil en fonction du compromis SOC (réduire FP vs réduire FN). La ligne pointillée correspond à la prévalence de la classe Attack dans le test.}
  \label{fig:pr-binary}
\end{figure}

\subsection{Classification multi-classes : familles}
La tâche \emph{familles} vise à \emph{tracker} le type d'attaque à un niveau exploitable.
Le tableau~\ref{tab:fam} montre que XGBoost est meilleur en moyenne (balanced accuracy \num{0.784}, MCC \num{0.752}), tandis que la régression logistique souffre davantage des non-linéarités et du déséquilibre.
Les métriques \emph{pondérées} (dominées par les classes majoritaires) sont très élevées, mais les métriques \emph{macro} restent basses ; cela reflète le fait que les classes minoritaires sont difficilement apprises et/ou absentes du test.

\begin{table}[H]
  \centering
  \caption{Résultats multi-classes (familles) sur le test.}
  \label{tab:fam}
  \resizebox{\textwidth}{!}{\input{tables/results_multiclass_families.tex}}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/confusion_fam_logreg.png}
  \caption{Matrice de confusion (familles) -- régression logistique. Les classes absentes du test apparaissent en lignes nulles (limite du group split sur un subset).}
  \label{fig:cm-fam-lr}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/confusion_fam_rf.png}
  \caption{Matrice de confusion (familles) -- forêt aléatoire.}
  \label{fig:cm-fam-rf}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/confusion_fam_xgb.png}
  \caption{Matrice de confusion (familles) -- XGBoost.}
  \label{fig:cm-fam-xgb}
\end{figure}

\subsection{Classification multi-classes : sous-types}
Le niveau \emph{sous-types} augmente la granularité mais exacerbe les difficultés : plus de classes, souvent plus rares, et risque de classes manquantes en train/test.
Le notebook met en place un filtrage et un regroupement (\emph{Other}) puis plafonne chaque classe à \num{10000} flows pour stabiliser l'entraînement.
Sur ce subset, la régression logistique obtient la meilleure balanced accuracy (\num{0.720}) tandis que XGBoost maximise l'AUPRC macro (\num{0.869}).

\begin{table}[H]
  \centering
  \caption{Résultats multi-classes (sous-types filtrés) sur le test.}
  \label{tab:st}
  \resizebox{\textwidth}{!}{\input{tables/results_multiclass_subtypes.tex}}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/confusion_st_logreg.png}
  \caption{Matrice de confusion (sous-types filtrés) -- régression logistique.}
  \label{fig:cm-st-lr}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/confusion_st_rf.png}
  \caption{Matrice de confusion (sous-types filtrés) -- forêt aléatoire.}
  \label{fig:cm-st-rf}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.98\textwidth]{figures/confusion_st_xgb.png}
  \caption{Matrice de confusion (sous-types filtrés) -- XGBoost.}
  \label{fig:cm-st-xgb}
\end{figure}

\begin{table}[H]
  \centering
  \caption{Synthèse : meilleurs modèles selon la métrique principale de la tâche (issue du notebook).}
  \label{tab:best-models}
  \resizebox{\textwidth}{!}{\input{tables/best_models.tex}}
\end{table}

\section{Analyse et discussion des résultats}
\label{sec:discussion}
\subsection{Détection binaire : compromis FP/FN}
Le tableau~\ref{tab:bin-sup} illustre un point clé SOC : XGBoost a un rappel très élevé (FN=\num{522}), mais génère beaucoup de faux positifs (FP=\num{6685}).
À seuil fixe ($0.5$), il peut être difficilement déployable sans mécanisme de triage, de corrélation ou d'ajustement de seuil.
À l'inverse, la PCA reconstruction (Tableau~\ref{tab:bin-unsup}) combine un bon rappel et un nombre faible de faux positifs, ce qui peut en faire un détecteur de première ligne lorsque les labels sont partiels.

\subsection{Multi-classes et effet du group split}
Le group split est indispensable pour éviter la fuite ; en contrepartie, il peut conduire à des classes absentes en test lorsque le subset est limité.
Dans notre exécution, le test \emph{familles} ne contient que 4 familles (Benign, DDoS, DoS, Mirai), et le test \emph{sous-types} ne couvre qu'un sous-ensemble des classes filtrées.
Cela explique en partie l'écart entre métriques macro et pondérées, et limite l'interprétation des performances sur les classes rares.
Une extension naturelle consiste à répéter l'expérience sur plusieurs splits (ou une validation croisée \emph{par groupe}) pour stabiliser les métriques.

\subsection{Confusions dominantes}
Les tableaux~\ref{tab:topconf-fam} et \ref{tab:topconf-st} listent les principales confusions (XGBoost pour familles, régression logistique pour sous-types).
On observe notamment une confusion Benign$\rightarrow$Recon et DDoS$\leftrightarrow$Mirai au niveau familles, suggérant des profils de flux partiellement similaires sur le subset chargé.
Au niveau sous-types, la classe agrégée \emph{Other} est la source principale d'erreurs : elle regroupe des attaques hétérogènes et devient naturellement difficile à séparer des classes spécifiques (DoS SYN Flood, Benign, Mirai).

\begin{table}[H]
  \centering
  \caption{Top confusions (familles) pour le meilleur modèle XGBoost sur le test.}
  \label{tab:topconf-fam}
  \input{tables/top_confusions_families.tex}
\end{table}

\begin{table}[H]
  \centering
  \caption{Top confusions (sous-types filtrés) pour le meilleur modèle (régression logistique) sur le test.}
  \label{tab:topconf-st}
  \input{tables/top_confusions_subtypes.tex}
\end{table}

\subsection{Interprétabilité : importance des features (XGBoost binaire)}
En cybersécurité, l'interprétabilité aide à valider qu'un modèle exploite des signaux plausibles, et à construire des règles de \emph{sanity-check} (monitoring, détection de dérive).
La figure~\ref{fig:xgb-imp} montre les 20 variables les plus importantes (importance \emph{gain}) pour le modèle XGBoost binaire.
On observe que des statistiques de longueurs de paquets, d'inter-arrivées (\emph{IAT}) et des compteurs de drapeaux TCP (SYN/RST/CWR) dominent, ce qui est cohérent avec des attaques générant des patterns temporels et des signatures de handshake atypiques.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.95\textwidth]{figures/xgb_feature_importance_binary.png}
  \caption{Top-20 features du modèle XGBoost (binaire) selon l'importance \emph{gain}. Cette lecture reste dépendante du subset chargé et de la configuration du modèle.}
  \label{fig:xgb-imp}
\end{figure}

\subsection{Lecture cyber par niveau}
\paragraph{Niveau 1 -- Détecter (binaire).}
L'objectif prioritaire est d'éviter des attaques manquées (FN) tout en réduisant l'alert fatigue (FP).
Les résultats montrent qu'un modèle \emph{supervisé} très performant en AUPRC peut générer trop d'alertes à seuil fixe, d'où l'importance de la courbe PR (Fig.~\ref{fig:pr-binary}) et d'un calibrage de seuil en production.
\paragraph{Niveau 2A -- Tracker haut niveau (familles).}
La classification familles aide à prioriser et à orienter l'investigation.
Sur le subset, XGBoost domine en balanced accuracy (Tableau~\ref{tab:fam}), mais l'évaluation doit être renforcée (split couvrant toutes les classes, répétitions).
\paragraph{Niveau 2B -- Tracker fin (sous-types).}
La granularité fine nécessite davantage de données par sous-type.
Le filtrage et la classe \emph{Other} stabilisent l'apprentissage mais introduisent une classe intrinsèquement hétérogène, ce qui se traduit par des confusions concentrées sur \emph{Other} (Tableau~\ref{tab:topconf-st}).

\section{Attaques adversariales et impact sur les modèles}
\label{sec:adv}
\subsection{Menace considérée}
Nous étudions une attaque d'évasion de type FGSM \cite{goodfellow2015fgsm} contre une régression logistique binaire.
Dans le notebook, les entrées sont déjà standardisées (centrage-réduction) ; l'attaque applique une perturbation $\ell_\infty$ de norme $\varepsilon$ dans cet espace normalisé.
Cette hypothèse simplifie la génération d'exemples adversariaux, mais ne modélise pas directement une modification réaliste des paquets réseau : l'intérêt est de quantifier une \emph{sensibilité} du classifieur.

\subsection{Résultats}
Le tableau~\ref{tab:adv} et la figure~\ref{fig:adv} montrent une dégradation extrêmement rapide de l'accuracy robuste : dès $\varepsilon=\num{0.1}$, elle tombe à \num{0.172}, et devient quasi nulle à partir de $\varepsilon=\num{0.2}$.
Ces résultats sont cohérents avec la vulnérabilité connue des modèles linéaires aux perturbations dirigées en grande dimension.

\begin{table}[H]
  \centering
  \caption{Accuracy robuste (binaire) en fonction de $\varepsilon$ pour une attaque FGSM sur régression logistique.}
  \label{tab:adv}
  \input{tables/adversarial_fgsm.tex}
\end{table}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\textwidth]{figures/adv_fgsm_robust_accuracy.png}
  \caption{Accuracy robuste vs $\varepsilon$ (FGSM, régression logistique).}
  \label{fig:adv}
\end{figure}

\subsection{Pistes de mitigation}
Sans prétendre à une défense complète, plusieurs pistes sont directement actionnables :
\begin{itemize}
  \item \textbf{Adversarial training} sur une plage de $\varepsilon$ compatible avec la sémantique des features.
  \item \textbf{Contraintes de validité} sur les features (bornes, invariants) et détection d'entrées hors distribution.
  \item \textbf{Choix de modèles} et ensembles : diversifier les inductive biases (linéaire + arbres) et surveiller la dérive.
  \item \textbf{Seuils adaptatifs} et corrélation multi-sources : réduire l'impact d'un contournement isolé.
\end{itemize}

\section{Conclusion et perspectives cybersécurité}
Ce projet met en place une chaîne \emph{batch} complète (ingestion, nettoyage, split anti-fuite, standardisation, entraînement, évaluation) sur \DatasetName{}.
En détection binaire, les méthodes non supervisées (notamment PCA reconstruction) offrent un compromis FP/FN très compétitif, tandis que XGBoost maximise l'AUPRC mais nécessite un choix de seuil adapté au SOC.
En suivi multi-classes, XGBoost est le meilleur au niveau familles sur le subset considéré, et la régression logistique atteint la meilleure balanced accuracy au niveau sous-types filtrés, avec des erreurs dominées par la classe \emph{Other}.
Enfin, l'expérience FGSM souligne l'importance de considérer la robustesse adversariale dès la conception : même un modèle simple peut être fortement contourné si l'attaquant peut perturber les features.
En perspectives : (i) répéter l'évaluation sur plusieurs splits \emph{par fichier}, (ii) élargir le subset (budgets) pour couvrir davantage de familles/sous-types en test, et (iii) étendre l'étude adversariale aux modèles d'arbres et au multiclass avec des attaques compatibles tabulaire.

\newpage
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
